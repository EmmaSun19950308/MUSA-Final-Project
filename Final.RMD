---
title: "Final Project: BeRail, Be Easy"
author: "Emma Sun, Yiming Ma"
date: "12/15/2020"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
    theme: flatly
    highlight: monochrome
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## I. Introduction

![ ](/Users/penguin/Box Sync/GitHub/Final Project/banner.png)

##                                               


Belgium has a decent public transport network, offering accessible and efficient travel across the country. Although geographically small, Belgium is bursting with popular cities like Brussels,Liege,Charleroi, Gent, and Antwerpen, connected by the vast network of the train system, connected by the vast network of the train system. Thanks to the dense railway network, taking trains has become the most efficient way to commute and travel among towns and cities. 

However, with the increasing demand of taking trains as well as the unbalanced development across the country, some train lines can be extremely busy with a high occupancy level, while other lines might be under operated. City planners and train conductors are super interested in the tool which can help them analyze and estimate the train occupancy level, so that they can develop a better understanding of optimizing railway operation across the country. 

Existing projects and applications have made efforts to address pertinent problems but more from the perspective of customers. They have leveraged the pre-existing data and real-time data to help passengers direct a route. This project as well as the synchronous App, nevertheless, targets transportation planners including city planners and train conductors, and is dedicated to smarter decisions and better service. To facilitate the effort, this project employs regression models with comprehensive features to predict occupancy level of each train line, and embeds the algorithm into the developing App to help monitor and analyze the occupancy issue. 

Specifically, this project builds a Logistic Regression model to predict high/low occupancy rate of trains in Belgium on the station's basis by integrating various data sources. Model is validated across 100 folders and space patterns. The project offers insights on resource allocation, route optimization for city planners and train conductors.  


![Belgium Railway Map](/Users/penguin/Box Sync/GitHub/Final Project/map.png)



[Click](https://youtu.be/PrhAjW-pVkQ) here to access the BeRail introduction video. 




```{r Setup, message=FALSE, warning=FALSE, include=FALSE}
# 1. Load library
library(tidyverse)
library(sf)
library(QuantPsyc)
library(RSocrata)
library(viridis)
library(caret)
library(spatstat)
library(spdep)
library(FNN)
library(grid)
library(gridExtra)
library(knitr)
library(kableExtra)
library(tidycensus)
library(nnet)
library(foreign)
library(stargazer)
library(reshape2)
library(class)
library(MASS)
library(dplyr)
library(tidyr)
library(lubridate)
library(plotly)
library(ggmap)
library(data.table)
library(gganimate)
library(plotROC)
library(pROC)


# 2. Identify functions
mapTheme <- function(base_size = 12) {
  theme(
    text = element_text( color = "black"),
    plot.title = element_text(size = 15,colour = "black"),
    plot.subtitle=element_text(face="italic"),
    plot.caption=element_text(hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),axis.title = element_blank(),
    axis.text = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=2),
    strip.text.x = element_text(size = 14))
}

plotTheme <- function(base_size = 12) {
  theme(
    text = element_text( color = "black"),
    plot.title = element_text(color = "#5b7375", size=15, face="bold"),
    plot.subtitle = element_text(face="italic"),
    plot.caption = element_text(hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),
    panel.grid.major = element_line("#E5E5E5", size = 0.1),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=2),
    strip.background = element_rect(fill = "#E5E5E5", color = "white"),
    strip.text = element_text(size=12),
    axis.title = element_text(size=12),
    axis.text = element_text(size=10),
    plot.background = element_blank(),
    legend.background = element_blank(),
    legend.title = element_text(colour = "black", face = "italic"),
    legend.text = element_text(colour = "black", face = "italic"),
    strip.text.x = element_text(size = 14)
  )
}

#3. Load Quantile break functions

qBr <- function(df, variable, rnd) {
  if (missing(rnd)) {
    as.character(quantile(round(df[[variable]],0),
                          c(.01,.2,.4,.6,.8), na.rm=T))
  } else if (rnd == FALSE | rnd == F) {
    as.character(formatC(quantile(df[[variable]]), digits = 3),
                 c(.01,.2,.4,.6,.8), na.rm=T)
  }
}

q5 <- function(variable) {as.factor(ntile(variable, 5))}

Modes <- function(x) {
  ux <- unique(x)
  tab <- tabulate(match(x, ux))
  ux[tab == max(tab)]
}

# for calculating average nearest neighbor distance.

nn_function <- function(measureFrom,measureTo,k) {
  measureFrom_Matrix <- as.matrix(measureFrom)
  measureTo_Matrix <- as.matrix(measureTo)
  nn <-   
    get.knnx(measureTo, measureFrom, k)$nn.dist
  output <-
    as.data.frame(nn) %>%
    rownames_to_column(var = "thisPoint") %>%
    gather(points, point_distance, V1:ncol(.)) %>%
    arrange(as.numeric(thisPoint)) %>%
    group_by(thisPoint) %>%
    dplyr::summarize(pointDistance = mean(point_distance)) %>%
    arrange(as.numeric(thisPoint)) %>% 
    dplyr::select(-thisPoint) %>%
    pull() 
  
  return(output)  
}


palette7 <- c('#4c281a','#8f4405',"#ff6d69","#0be7fb","#3182bd","#08519c",'#f9c37a')
palette5 <- c("#eff3ff","#bdd7e7","#6baed6","#3182bd","#08519c")
palette4 <- c("#eb3333","#312c9e","#ff724e",'#1b8f84')
palette3 <- c('#B22222',"#41c447","#005582" )
palette2 <- c("#eadd46","#485123")



```



## II. Data Loading and Feature Engineering

### 2.1 Data Loading

This project leverages 6 datasets in total. 

*    `occupancy`: This is the fundamental dataset provided on [Kaggle](https://www.kaggle.com/c/train-occupancy-prediction/discussion/27828#latest-156701) to identify the occupancy level of trains in Belgium in 2016. This project only works on the training set. 

*    `stations`: This data [table](https://github.com/GillesVandewiele/KaggleTrainOccupancy/blob/master/line_info.csv) contains all information of train stations. The main hub stations in Belgium are Bruxelles Midi/Brussel Zuid, Brussel Centraal, Brussel Noord, Antwerpen Centraal, Gent Sint-Pieters and Luik Guillemins. At these train stations, it's possible to connect to trains to Belgium’s main cities and many international destinations.

*    `weather`: The integrated [dataset](https://github.com/GillesVandewiele/KaggleTrainOccupancy) contains temperature, humidity, windspeed, and visibility data of each station per hour from July 2016 to October 2016. 

*    `facility`: The [dataset](https://github.com/GillesVandewiele/KaggleTrainOccupancy) identifies the amenities of each station. Stations in Belgium usually have excellent facilities, often including: luggage lockers, foreign exchange desks, restaurants and cafés, tourist information offices, ATM cash machines, elevators and escalators, access for disabled passengers. To make it simple, we sum all facilities of each station when using this variable. 

*    `rail`: A [shapefile](https://mapcruzin.com/free-belgium-arcgis-maps-shapefiles.htm) to show the railway pattern in Belgium.

*    `lines`: By connecting different stations, this [dataset](https://github.com/GillesVandewiele/KaggleTrainOccupancy) identifies train lines across Belgium.


```{r Data loading, message=FALSE, warning=FALSE, include=FALSE}
## 1. occupancy data
occupancy = read.csv("trains_train.csv") 

## 2. station data
stations0 <- read.csv("stations.csv")
stations.sf <- 
  stations0 %>% 
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326, agr = "constant") %>%
  st_transform(31370)

stations <- stations.sf %>%
  separate(URI, c("res", "station_name"), "NMBS/")%>%
  select(station_name,name,country.code,avg_stop_times,
         geometry)


## 3. Weather data
W701 <- read.csv("weather_data_july_1.csv")
W702 <- read.csv("weather_data_july_2.csv")
W801 <- read.csv("weather_data_aug_1.csv")
W802 <- read.csv("weather_data_aug_2.csv")
W901 <- read.csv("weather_data_sep_1.csv")
W902 <- read.csv("weather_data_sep_2.csv")
W101 <- read.csv("weather_data_oct_1.csv")
W102 <- read.csv("weather_data_oct_2.csv")

weather <- rbind(W701,W702,W801,W802,W901,W902,W101,W102) %>%
  mutate(interval60 = ymd_hms(date_time))



## 4. Demographic data: population density
### population
### https://ec.europa.eu/eurostat/cache/metadata/en/demo_r_gind3_esms.htm
### topo data
### https://gisco-services.ec.europa.eu/distribution/v1/nuts-2016.html
# bel <- st_read("NUTS_RG_60M_2016_4326_LEVL_3.shp") 
# popdens <- read.csv("demo_r_d2jan_1_Data.csv")
# belpopden <- bel %>%
  # left_join(dplyr::select(popdens, c(GEO, Value)), by = c("FID" = "GEO")) %>%
  # st_transform(31370)



## 5. Facility data

facility <- read.csv("facilities.csv")
facility[is.na(facility)] <- 0 

facility <- 
  facility %>% 
  mutate(facility_sum = select(.,ticket_vending_machine:audio_induction_loop) %>% 
           rowSums()) %>% 
  select(name,facility_sum)

stations <- merge(stations, facility,by.x="name",all.x=TRUE) 

## 6. Railway data
### https://mapcruzin.com/free-belgium-arcgis-maps-shapefiles.htm
rail <- st_read("belgium-railways-shape/railways.shp") %>%
  st_transform(4326)

## 7. Line Info
lines <- read.csv('line_info.csv')


# Initial Dataset

data <-
  occupancy %>%
  mutate(from = as.character(from), to = as.character(to)) %>%
  left_join(dplyr::select(stations, station_name), by = c("from" = "station_name")) %>%
  st_sf() %>% 
  mutate(from.X = st_coordinates(.)[,1], from.Y = st_coordinates(.)[,2]) %>%
  st_drop_geometry() %>%
  left_join(dplyr::select(stations, station_name), by = c("to" = "station_name")) %>%
  st_sf() %>% 
  mutate(to.X = st_coordinates(.)[,1], to.Y = st_coordinates(.)[,2]) %>%
  st_drop_geometry() %>%
  mutate(distance = sqrt((from.X - to.X)^2 + (from.Y - to.Y)^2)) %>%
  arrange(-distance) 


data <- data %>%
  mutate(datetime <- paste(date,time),
         datetime = parse_date_time(datetime, '%y-%m-%d %I:%M:%S %p'),
         interval60 = floor_date(ymd_hms(datetime), unit = "hour"),
         interval15 = floor_date(ymd_hms(datetime), unit = "15 mins"),
         week = week(interval60),
         dotw = wday(interval60)) %>%
  select(-`datetime <- paste(date, time)`)

data <- data %>%
  mutate(day = case_when(
     dotw==1~"Mon",
    dotw==2~"Tue",
    dotw==3~"Wed",
    dotw==4~"Thu",
    dotw==5~"Fri",
    dotw==6~"Sat",
    dotw==7~"Sun"
  )) %>%
  select(-dotw) 


data$vehicle_type <- gsub("[^a-zA-Z]", "", data$vehicle) 
data$vehicle_type[data$vehicle_type==""] <- "undefined"
data$vehicle_type[data$vehicle_type=="ic"] <- "ICE"

## final data: departure station data
data_f_0 <-  merge(data, stations,  by.x = "from", by.y = "station_name",all.x = TRUE) %>%
   st_as_sf()

data_f_00 <- merge(data_f_0,weather,by.x=c("name","interval60"),by.y=c("station_name","interval60"),all.x = TRUE)


## final data: destination station data
data_t_0 <-  merge(data, stations,  by.x = "to", by.y = "station_name",all.x = TRUE) %>%
   st_as_sf()

data_t_00 <- merge(data_t_0,weather,by.x=c("name","interval60"),by.y=c("station_name","interval60"),all.x = TRUE)

```



### 2.2 Feature Engineering

To enrich the preliminary datasets provided above and build a robust model, this project generates plenty of features to show characteristics of train stations and train operations:

*    **Station density**: By leveraging `nn_function`, we create `stationsdist` to show the distance of the nearest three other stations around each station.

*    **Station importance**: Measured by population size, we filter out the five biggest cities, and we create `majc_nn5` to show the distance between each station to the major cities.

*    **Station occupancy level**: We generate a series of features to identify the proportions of each occupancy level in this station. To make it more accurate, we conduct the calculation for the departure stations and destination stations separately. 

*    **Station group occupancy level**: Addition to the occupancy level of each station, we also generate three more features to show the average proportion of each occupancy level of station groups. Each group consists of the station itself as well as the three nearest stations. 

*    **Station popularity**: To show how busy one station can be, we calculate the connection number of each station. 
Occupancy level time lag: Creating time lag variables will add additional nuance about the demand during a given time period.  



#### 2.2.1 Station Density

Calculate the distance of nearest **three** stations around each station and show the outcome by occupancy level.

```{r station density, echo=TRUE, message=FALSE, warning=FALSE}
stations_copy <- stations

stations_copy$stationsdist <- nn_function(st_coordinates(stations), st_coordinates(stations), 3)

```


#### 2.2.2 Distance of Stations to Major Cities

Codes below calculate the distances of each station to the five major cities: **Brussels**,**Liege**,**Charleroi**, **Gent**, and **Antwerpen** measured by population size. 







```{r Distance of Major City, echo=TRUE, message=FALSE, warning=FALSE}
name <- c("Brussels","Liege","Charleroi", "Gent", "Antwerpen")
lat <- c(50.85045,50.63373, 50.41136, 51.05, 51.21989)
lon <- c(4.34878, 5.56749, 4.44448, 3.71667, 4.40346)

majorcities <- tibble(name, lat, lon) %>%
  st_as_sf(coords = c("lon","lat"), crs = 4326, agr = "constant") %>%
  st_transform(31370)

stations_copy$majc_nn5 <- nn_function(st_coordinates(stations), st_coordinates(majorcities), 5)

stations_copy <-
  stations_copy %>%
  mutate(Brussels = sqrt((st_coordinates(.)[,1] - st_coordinates(majorcities)[1,1])^2 + (st_coordinates(.)[,2] - st_coordinates(majorcities)[1,2])^2)) %>%
  mutate(Liege = sqrt((st_coordinates(.)[,1] - st_coordinates(majorcities)[2,1])^2 + (st_coordinates(.)[,2] - st_coordinates(majorcities)[2,2])^2)) %>%
  mutate(Charleroi = sqrt((st_coordinates(.)[,1] - st_coordinates(majorcities)[3,1])^2 + (st_coordinates(.)[,2] - st_coordinates(majorcities)[3,2])^2)) %>%
  mutate(Gent = sqrt((st_coordinates(.)[,1] - st_coordinates(majorcities)[4,1])^2 + (st_coordinates(.)[,2] - st_coordinates(majorcities)[4,2])^2)) %>%
  mutate(Antwerpen = sqrt((st_coordinates(.)[,1] - st_coordinates(majorcities)[5,1])^2 + (st_coordinates(.)[,2] - st_coordinates(majorcities)[5,2])^2)) 

```


#### 2.2.3 Occupancy Level Proportion of Each Station

Codes below are to calculate the proportion of each occupancy level for each origin station and destination station respectively.

```{r Occupancy Level Proportion of Each Station, echo=TRUE, message=FALSE, warning=FALSE}

## Origin Station
data_f_00_h <- data_f_00 %>%
  filter(occupancy=='high')

data_f_00_m <- data_f_00 %>%
  filter(occupancy=='medium')

data_f_00_l <- data_f_00 %>%
  filter(occupancy=='low')


sta_from_total <- as.data.frame(table(data_f_00$from)) %>% 
  filter(Var1!='(null)') %>% 
  mutate(station_f=as.character(Var1)) %>%
  mutate(F_total=Freq) %>%
  select(3,4)

sta_from_h <- as.data.frame(table(data_f_00_h$from)) %>% 
  filter(Var1!='(null)') %>% 
  mutate(station_f=as.character(Var1)) %>%
  mutate(F_H_freq=Freq) %>%
  select(3,4)

sta_from_m <- as.data.frame(table(data_f_00_m$from)) %>% 
  filter(Var1!='(null)') %>% 
  mutate(station_f=as.character(Var1)) %>%
  mutate(F_M_freq=Freq) %>%
  select(3,4) 

sta_from_l <- as.data.frame(table(data_f_00_l$from)) %>% 
  filter(Var1!='(null)') %>% 
  mutate(station_f=as.character(Var1)) %>%
  mutate(F_L_freq = Freq) %>%
  select(3,4)  


## Destination Station
data_t_00_h <- data_t_00 %>%
  filter(occupancy=='high')

data_t_00_m <- data_t_00 %>%
  filter(occupancy=='medium')

data_t_00_l <- data_t_00 %>%
  filter(occupancy=='low')


sta_to_total <- as.data.frame(table(data_t_00$to)) %>% 
  filter(Var1!='(null)') %>% 
  mutate(station_t = as.character(Var1)) %>%
  mutate(T_total = Freq) %>%
  select(3,4)

sta_to_h <- as.data.frame(table(data_t_00_h$to)) %>% 
  filter(Var1!='(null)') %>% 
  mutate(station_t = as.character(Var1)) %>%
  mutate(T_H_freq=Freq) %>%
  select(3,4)

sta_to_m <- as.data.frame(table(data_t_00_m$to)) %>% 
  filter(Var1!='(null)') %>% 
  mutate(station_t=as.character(Var1)) %>%
  mutate(T_M_freq=Freq) %>%
  select(3,4) 

sta_to_l <- as.data.frame(table(data_t_00_l$to)) %>% 
  filter(Var1!='(null)') %>% 
  mutate(station_t=as.character(Var1)) %>%
  mutate(T_L_freq = Freq) %>%
  select(3,4)  


stations_occ <- merge(stations,sta_from_total,by.x="station_name",by.y='station_f',all.x=T)
stations_occ <- merge(stations_occ,sta_from_h,by.x="station_name",by.y='station_f',all.x=T)
stations_occ <- merge(stations_occ,sta_from_m,by.x="station_name",by.y='station_f',all.x=T)
stations_occ <- merge(stations_occ,sta_from_l,by.x="station_name",by.y='station_f',all.x=T)

stations_occ <- merge(stations_occ,sta_to_total,by.x="station_name",by.y='station_t',all.x=T)
stations_occ <- merge(stations_occ,sta_to_h,by.x="station_name",by.y='station_t',all.x=T)
stations_occ <- merge(stations_occ,sta_to_m,by.x="station_name",by.y='station_t',all.x=T)
stations_occ <- merge(stations_occ,sta_to_l,by.x="station_name",by.y='station_t',all.x=T)

stations_occ$F_H_com <- stations_occ$F_H_freq/stations_occ$F_total
stations_occ$F_M_com <- stations_occ$F_M_freq/stations_occ$F_total
stations_occ$F_L_com <- stations_occ$F_L_freq/stations_occ$F_total
stations_occ$T_H_com <- stations_occ$T_H_freq/stations_occ$T_total
stations_occ$T_M_com <- stations_occ$T_M_freq/stations_occ$T_total
stations_occ$T_L_com <- stations_occ$T_L_freq/stations_occ$T_total
stations_occq <- select(stations_occ,1,14,15,16,17,18,19,20)

```



#### 2.2.4 Average Occupancy Level Proportion by Station Group

Codes below calculate the average occupancy level proportion of the nearest **three** stations of each stations.

```{r  Average Occupancy Level Proportion by Station Group , echo=TRUE, message=FALSE, warning=FALSE}
neighborList <- knn2nb(knearneigh(st_coordinates(stations), 3))
occupancy$from <- as.character(occupancy$from)
occupancy$to <- as.character(occupancy$to)

getnb_from <- function(x,i, from, occ){
    nbcount = occupancy %>%
      left_join(dplyr::select(stations_copy, c(station_name, stationsdist)), by = c(from = "station_name")) %>%
      filter(from %in% stations$station_name[neighborList[[i]]]) %>%
      tally()
    nbcount1 = occupancy %>%
      left_join(dplyr::select(stations_copy, c(station_name, stationsdist)), by = c(from = "station_name")) %>%
      filter(from %in% stations$station_name[neighborList[[i]]] & occupancy == occ) %>%
      tally()
    nbcount2 = nbcount1/nbcount
  return(nbcount2[,1])
}

#avg composition of low occupancy from neighbor from stations
nblist = list()
for (i in 1:length(neighborList)){
  nblist[[i]] = getnb_from(neighborList,i,"from","low")
}
stations_copy$nb_occ_f_low <- nblist

#avg composition of medium occupancy from neighbor from stations
nblist = list()
for (i in 1:length(neighborList)){
  nblist[[i]] = getnb_from(neighborList,i,"from","medium")
}
stations_copy$nb_occ_f_medium <- nblist

#avg composition of high occupancy from neighbor from stations
nblist = list()
for (i in 1:length(neighborList)){
  nblist[[i]] = getnb_from(neighborList,i,"from","high")
}
stations_copy$nb_occ_f_high <- nblist

#avg composition of low occupancy from neighbor to stations
nblist = list()
for (i in 1:length(neighborList)){
  nblist[[i]] = getnb_from(neighborList,i,"to","low")
}
stations_copy$nb_occ_t_low <- nblist


#avg composition of medium occupancy from neighbor to stations
nblist = list()
for (i in 1:length(neighborList)){
  nblist[[i]] = getnb_from(neighborList,i,"to","medium")
}
stations_copy$nb_occ_t_medium <- nblist


#avg composition of high occupancy from neighbor to stations
nblist = list()
for (i in 1:length(neighborList)){
  nblist[[i]] = getnb_from(neighborList,i,"to","high")
}
stations_copy$nb_occ_t_high <- nblist
```




#### 2.2.5 Station Popularity

Then we explore the popularity of each station, in other words, we can calculate the number of lines connected to each origin station and destination station respectively. 


```{r Station Popularity, echo=TRUE, message=FALSE, warning=FALSE}
connect <- function(line,stt){
  stt <- as.data.frame(stt) %>% 
    select(1)
  stt$connect <- NA

  for(i in seq(1:nrow(stt))){
    if(length(table(line$stops==stt[i,1]))==2){
      line_i <- line %>% 
        filter(stops==stt[i,1])
      stt$connect[i] <- nrow(line_i)
      }
    }
  return(stt)
}


lines_connect <- lines %>% 
  select(5,7) %>% 
  mutate(stops = gsub("\\[","",stopping_station_ids)) %>% 
  mutate(stops = gsub("\\]","",stops)) %>% 
  mutate(stops = gsub("'",  "",stops)) %>% 
  mutate(stops = gsub(" ",  "",stops)) %>% 
  unique() %>% 
  select(3) %>% 
  separate_rows(stops, sep=",") %>%
  group_by(stops) %>%
  summarize(connections = n())

stations_occ_line <- merge(stations_occq, lines_connect, 
                           by.x = "station_name", by.y = "stops", all.x = TRUE)

stations_final <- merge(st_drop_geometry(stations_copy),
                        st_drop_geometry(stations_occ_line),
                        by = "station_name") %>%
  select(-name,-country.code,-avg_stop_times,-facility_sum)
```



#### 2.2.6 Occupancy Level Time Lag

Since the period of given data barely covers holidays, thus this analysis creates `lagHour`, `lag2Hours`,`lag3Hours`, `lag4Hours`, and `lag12Hours` to show occupancy level of each shift before and after a certain time whth holiday effect ruled out. 


```{r Time Lag, message=FALSE, warning=FALSE, include=FALSE}
data_f <- data_f_00 %>%
  left_join(stations_final, by = c('from' = "station_name")) 

data_t <- data_t_00 %>%
  left_join(stations_final, by = c('from' = "station_name")) 

data_f <- data_f %>% 
  mutate(occ_num = as.numeric(case_when(
    data_f$occupancy == "high" ~ 3,
    data_f$occupancy == "medium" ~ 2,
    data_f$occupancy == "low" ~ 1,
  )))

data_f <- 
  data_f %>% 
  arrange(from, interval60) %>% 
  mutate(lagHour = dplyr::lag(occ_num,1),
         lag2Hours = dplyr::lag(occ_num,2),
         lag3Hours = dplyr::lag(occ_num,3),
         lag4Hours = dplyr::lag(occ_num,4),
         lag12Hours = dplyr::lag(occ_num,12)) %>%
  mutate(time_of_day = case_when(hour(interval60) < 7 | hour(interval60) > 18 ~ "Overnight",
                                 hour(interval60) >= 7 & hour(interval60) < 10 ~ "AM Rush",
                                 hour(interval60) >= 10 & hour(interval60) < 15 ~ "Mid-Day",
                                 hour(interval60) >= 15 & hour(interval60) <= 18 ~ "PM Rush"))

data_t <- data_t %>% 
  mutate(occ_num = as.numeric(case_when(
    data_t$occupancy == "high" ~ 3,
    data_t$occupancy == "medium" ~ 2,
    data_t$occupancy == "low" ~ 1,
  )))

data_t <- 
  data_t %>% 
  arrange(to, interval60) %>% 
  mutate(lagHour = dplyr::lag(occ_num,1),
         lag2Hours = dplyr::lag(occ_num,2),
         lag3Hours = dplyr::lag(occ_num,3),
         lag4Hours = dplyr::lag(occ_num,4),
         lag12Hours = dplyr::lag(occ_num,12)) %>%
  mutate(time_of_day = case_when(hour(interval60) < 7 | hour(interval60) > 18 ~ "Overnight",
                                 hour(interval60) >= 7 & hour(interval60) < 10 ~ "AM Rush",
                                 hour(interval60) >= 10 & hour(interval60) < 15 ~ "Mid-Day",
                                 hour(interval60) >= 15 & hour(interval60) <= 18 ~ "PM Rush"))


```


## III. Exploratory Data Analysis

This section is divided into **five** subsections:

*    **Station Characteristics**: This subsection creates a series of maps to show the station density by occupancy level, station’s distance to major cities, high occupancy level proportion of each station, station popularity, facility characteristics.

*    **Weather Correlation**: This subsection focuses on the weather conditions and correlations on each OD set. 

*    **Serial Autocorrelation**: This subsection consists of three sets of plots, exhibiting train counts bu occupancy level on a general basis, weekend and weekdays basis, as well as a daily basis. 

*    **Spatial Autocorrelation**: This subsection creates animation to show the 20 busiest lines. 

*    **Space/Time Correlation**: This subsection creates two plots to show occupancy level across departure stations and destination stations by each week days. 


The findings in this section indicate that occupancy levels might be influenced by temporal and spatial factors, station existing characteristics and weather conditions.  


### 3.1 Stations Characteristics

#### 3.1.1 Station Density by Occupancy Level 

Plots below identify the station density across occupancy levels, and regardless of occupancy, the density is decreasing from the central part of the country to the periphery, indicating the overall occupancy level should be different between center and periphery. 

```{r Station Density by Occupancy Level, echo=TRUE, message=FALSE, warning=FALSE,fig.height = 4, fig.width = 8}
ggplot() +
  geom_sf(data = rail, color = "grey") +  
  geom_sf(data = data_f %>%
            filter(country.code == 'be'), 
          aes(color = stationsdist) ,size = 0.5)+
  labs(title="Station Density by Occupancy Level",
       subtitle = 'Distance of each station to the nearest three stations\n',
       caption = 'Figure 3.1.1')+ 
  scale_colour_viridis(direction = -1,
  discrete = FALSE, option = "plasma",
  name = 'Counts')+
  facet_wrap(~occupancy, ncol = 3) + 
  mapTheme()+
  plotTheme()  +
  theme(legend.position = "bottom")
```

#### 3.1.2 Distance of Stations to Major Cities

Plots below exhibits a similar patterns that more stations are clustering the central part of the country where there are more bigger cities.

![Belgium Big Cities](/Users/penguin/Box Sync/GitHub/Final Project/Five biggest cities.png)


```{r Distance of Stations to Major Cities, echo=TRUE, message=FALSE, warning=FALSE, fig.height = 4, fig.width = 8}
ggplot() +
  geom_sf(data = rail, color = "grey") +  
  geom_sf(data = data_f %>%
            filter(country.code == 'be'), 
          aes(color = majc_nn5) ,size = 0.5)+
  labs(title="Distance of Stations to Major Cities",
       subtitle = ' ',
       caption = 'Figure 3.1.2')+ 
  scale_colour_viridis(direction = -1,
  discrete = FALSE, option = "plasma",
  name = 'Counts')+
  facet_wrap(~occupancy, ncol = 3) + 
  mapTheme()+
  plotTheme()  +
  theme(legend.position = "bottom")


```

#### 3.1.3 High Occupancy Level Proportion of Each Station

The proportion of high occupancy level of each station does not show a specific regularity. It seems that lines to the west are busier compared to lines to the east. 



```{r High Occupancy Level Proportion of Each Station, echo=TRUE, message=FALSE, warning=FALSE}
ggplot() +
  geom_sf(data = rail, color = "grey") +  
  geom_sf(data = data_f %>%
            filter(country.code == 'be'), 
          aes(color = F_H_com) ,size = 0.5)+
  labs(title="High Occupancy Level Proportion of Each Station",
       subtitle = ' ',
       caption = 'Figure 3.1.3')+ 
  scale_colour_viridis(direction = -1,
  discrete = FALSE, option = "plasma",
  name = 'Ratio')+
  mapTheme()+
  plotTheme()  
  


```




#### 3.1.4 Station Popularity 

As an important feature, station popularity identifies how many lines depart from, arrive at or pass a certain station. Plot below obviously shows that primary station hubs are consistent with the big cities, which sheds a light on the potential high occupancy level. 


```{r Station Popularity , echo=TRUE, message=FALSE, warning=FALSE}

ggplot() +
  geom_sf(data = rail, color = "grey") +  
  geom_sf(data = data_f %>%
            filter(country.code == 'be'), 
          aes(color = connections) ,size = 0.5)+
  labs(title="Station Popularity Across Nation",
       subtitle = 'Counts of connections of each station\n',
       caption = 'Figure 3.1.4')+ 
  scale_colour_viridis(direction = -1,
  discrete = FALSE, option = "plasma",
  name = 'Counts')+
  mapTheme()+
  plotTheme() 
```


#### 3.1.5 Facility Characteristics 

Stations show a balance in terms of the facilities. Therefore, facility might not be a vital factor to affect customers' behaviors. 

```{r Facility, echo=TRUE, message=FALSE, warning=FALSE}

ggplot() +
  geom_sf(data = rail, color = "grey") +  
  geom_sf(data = data_f %>%
            filter(country.code == 'be'), 
          aes(color = facility_sum) ,size = 0.5)+
  labs(title="Facility Counts Across Stations",
       subtitle = 'Departure Station\n',
       caption = 'Figure 3.1.5')+ 
  scale_colour_viridis(direction = -1,
  discrete = FALSE, option = "plasma",
  name = 'Counts')+
  mapTheme()+
  plotTheme() 
```

### 3.2 Weather Correlation

As for weather features: humidity, wind speed, visibility and temperature, regardless of days and occupancy levels, more train shifts happen when visibility is around 9-10, while temperature is round 10 to 20. Humidity degree is around 60-100. But wind speeds are fluctuating all the time. 


```{r weather cha, echo=TRUE, message=FALSE, warning=FALSE, fig.height = 5, fig.width = 10}
grid.arrange(
  ggplot(data_f, aes(interval60,humidity)) + geom_line(color = "#6897BB") +
    labs(title="Weather characteristics: Humidity",
         x="Hour", y="Humidity") + 
    plotTheme(),
  ggplot(data_f, aes(interval60,windspeed)) + geom_line(color = "#6897BB") +
    labs(title="Weather characteristics: Wind Speed", 
         x="Hour", y="Wind Speed") + 
    plotTheme(),
  ggplot(data_f, aes(interval60,temperature)) + geom_line(color = "#6897BB") +
    labs(title="Weather characteristics: Temperature",
         x="Hour", y="temperature",
         caption="Figure 3.2.1") + 
    plotTheme(),
  ggplot(data_f, aes(interval60,visibility)) + geom_line(color = "#6897BB") +
    labs(title="Weather characteristics: Visibility",
         x="Hour", y="Visibility") + 
    plotTheme())
```


```{r Weather Correlation, echo=TRUE, message=FALSE, warning=FALSE}
ggplot(data_f %>% 
         mutate(hour = hour(datetime)) %>% 
         filter(occupancy == "high" | occupancy == "medium" | occupancy == "low"), 
       aes(temperature, color = day))+
  geom_freqpoly(binwidth = 1)+
  facet_wrap(~occupancy,ncol=3) +
  scale_colour_manual(values = palette7,
                      name = "Week Day") +
  labs(title="Train Counts Across Temperature by Occupancy Level",
       subtitle = "Belgium, 2016\n",
       caption = "Figure 3.2.2 ",
       x="Temperature", 
       y="Counts") +
  plotTheme()

ggplot(data_f %>% 
         mutate(hour = hour(datetime)) %>% 
         filter(occupancy == "high" | occupancy == "medium" | occupancy == "low"), 
       aes(humidity, color = day))+
  geom_freqpoly(binwidth = 1)+
  facet_wrap(~occupancy,ncol=3) +
  scale_colour_manual(values = palette7,
                      name = "Week Day") +
  labs(title="Train Counts Across Humidity by Occupancy Level",
       subtitle = "Belgium, 2016\n",
       caption = "Figure 3.2.3",
       x="Humidity", 
       y="Counts") +
  plotTheme()


ggplot(data_f %>% 
         mutate(hour = hour(datetime)) %>% 
         filter(occupancy == "high" | occupancy == "medium" | occupancy == "low"), 
       aes(windspeed, color = day))+
  geom_freqpoly(binwidth = 1)+
  facet_wrap(~occupancy,ncol=3) +
  scale_colour_manual(values = palette7,
                      name = "Week Day") +
  labs(title="Train Counts Across Windspeed by Occupancy Level",
       subtitle = "Belgium, 2016\n",
       caption = "Figure 3.2.4",
       x="Windspeed", 
       y="Counts") +
  plotTheme()

ggplot(data_f %>% 
         mutate(hour = hour(datetime)) %>% 
         filter(occupancy == "high" | occupancy == "medium" | occupancy == "low"), 
       aes(visibility, color = day))+
  geom_freqpoly(binwidth = 1)+
  facet_wrap(~occupancy,ncol=3) +
  scale_colour_manual(values = palette7,
                      name = "Week Day") +
  labs(title="Train Counts Across Visibility by Occupancy Level",
       subtitle = "Belgium, 2016\n",
       caption = "Figure 3.2.5",
       x="Visibility", 
       y="Counts") +
  plotTheme()

```


### 3.3 Serial Autocorrelation

The station occupancy level exhibits a strong serial pattern. From 6:00 am to 8:00 am, and 16:00 pm to 17:00 pm,  more stations are experiencing medium and high occupancy level, and the passengers’ volume sharply decreases in other time periods. For the stations with medium and high occupancy levels, no distinguished difference has been seen between weekdays and weekends. Regardless of weekdays or weekends, trains are generally not busy during 10:00 am - 15:00 pm. 

```{r count by day, echo=TRUE, message=FALSE, warning=FALSE}
ggplot(data_f %>% 
         mutate(hour = hour(datetime)))+
  geom_freqpoly(aes(hour, color = occupancy), binwidth = 1)+
  scale_colour_manual(values = palette3) +
  labs(title="Train Counts by Occupancy Level (General)",
       subtitle = 'Belgium, 2016\n',
       caption = "Figure 3.3.1",
       
       x="Hour of the Day", 
       y="Counts")+
  plotTheme()
```

```{r Counts by Week Periods, echo=TRUE, message=FALSE, warning=FALSE}
ggplot(data_f %>% mutate(hour = hour(datetime),
                             weekend = ifelse(day %in% c("Sun", "Sat"), "Weekend", "Weekday"))) +
  geom_freqpoly(aes(hour, color = weekend), binwidth = 1)+
  scale_color_manual(values = palette2,
                     name = 'Period') +
  labs(title="Train Counts by Occupancy Level (Week Periods)",
       subtitle = 'Belgium, 2016\n',
       caption = 'Figure 3.3.2',
       x="Hour of the Day", 
       y="Counts")+
  facet_wrap(~occupancy,ncol=3) +
  plotTheme()
```

```{r Counts by Week Day, echo=TRUE, message=FALSE, warning=FALSE}
ggplot(data_f %>% mutate(hour = hour(datetime))) +
  geom_freqpoly(aes(hour, color = day), binwidth = 1)+
  scale_color_manual(values = palette7,
                     name = 'Week Day') +
  labs(title="Train Counts by Occupancy Level (Week Days)",
       subtitle = 'Belgium, 2016\n',
       caption = 'Figure 3.3.3',
       x="Hour of the Day", 
       y="Counts")+
  facet_wrap(~occupancy,ncol=3) +
  plotTheme()
```

### 3.4 Spatial Autocorrelation

Station workloads are unbalanced across the nation. Occupancy level varies a lot across stations nationwide. Some stations are connecting more routes, while some stations are less popular. The animation at the right side indicates the top 20 busiest lines across the nation, and we can easily find that Brussel is an undoubtful transportation hub from which a least 150 different lines depart.

```{r Spatial Autocorrelation, echo=TRUE, message=FALSE, warning=FALSE}
test04 <- data %>%
  group_by(vehicle) %>%
  summarise(n = n()) %>%
  filter(n >= 12)
freq_v = c("IC1518","IC429","IC1515","IC407","P7305","IC1807","IC3631","1828","8015","IC1831","IC539","P7444","S83978", "IC1507","IC716","L557","S23665","IC3432","IC4317","S53586")

p1 <- ggplot() +
  geom_sf(data = rail, aes(color = "grey")) + 
  geom_sf(data=subset(data_f, data_f$vehicle %in% freq_v),aes(colour = vehicle),size=2,show.legend = "point")+ 
  labs(title="Top 20 Busiest Lines",
       subtitle = 'Departure Stations\n',
       caption = "Figure 3.4")+
  mapTheme()+
  plotTheme() +
  theme(legend.position = "bottom") + 
  transition_manual(factor(vehicle, levels = freq_v), cumulative = TRUE) 
 


## occupancy by lines: destination
p2 <- ggplot()+
  geom_sf(data=rail,aes(color = "grey"))+
  geom_sf(data=subset(data_t, data_t$vehicle %in% freq_v),aes(colour = vehicle),size=2,show.legend = "point")+ 
  labs(title="Top 20 Frequent Lines Plotted to Destination\n",
       caption = 'Figure')+
  mapTheme()+
  plotTheme() +
  theme(legend.position = "bottom") +  
  transition_manual(factor(vehicle, levels = freq_v), cumulative = TRUE)

gganimate::animate(p1,  duration=10,renderer = gifski_renderer())
```

### 3.5 Space/Time Correlation

Occupancy levels are influenced by both temporal and spatial factors. More trains depart from Tuesdays to Saturdays compared to other days during the week. On Mondays and Tuesdays, stations with medium and high occupancy levels spread from east to west, while on Tuesdays, Wednesdays, Thursdays, as well as Saturdays, stations in the south part of the Nation need to take more passengers. 

```{r Space/Time Correlation, echo=TRUE, message=FALSE, warning=FALSE, fig.height = 5, fig.width = 8}
ggplot() +
  geom_sf(data = rail, color = "grey") +  
  geom_sf(data = data_f %>%
            filter(country.code == 'be'), 
          aes(color = occupancy) ,size = 0.5)+
  labs(title="Occupancy Level Across Departure Stations by Week Days\n",
       caption = 'Figure 3.5.1')+ 
  facet_wrap(~day, nrow =2) +
  scale_colour_manual(values = palette3,
                      name = 'Occupancy') +
  mapTheme()+
  plotTheme() 

ggplot() +
  geom_sf(data = rail, color = "grey") +  
  geom_sf(data = data_t %>%
            filter(country.code == 'be'), 
          aes(color = occupancy) ,size = 0.5)+
  labs(title="Occupancy Level Across Destination Stations by Week Days\n",
       caption = 'Figure 3.5.2')+ 
  facet_wrap(~day, nrow =2) +
  scale_colour_manual(values = palette3,
                      name = 'Occupancy') +
  mapTheme()+
  plotTheme() 

```










## IV. Model Building and Prediction


### 4.1 Model Building

Since we are more concerned about whether the occupancy level is high or not, starting from the model building, this project is planning to transform the independent variable to `high_occ` which is a binomial variable, consisting of two levels: Yes and No to identify the occupancy level is high or not. Therefore, we will build a **Logistic Regression** model. After screening the features we built above, this project builds two models: one does not include time-lag features while the other does. The statistics summary of the two models are also shown below. 




```{r model, echo=TRUE, message=FALSE, warning=FALSE,results ='asis'}

# Create regression dataset
data_f <- data_f %>% 
  rowid_to_column(var = "rowIndex") 
  
data_f_reg <- data_f %>% 
  mutate(hour = hour(interval60),
         min = hour(interval15)) %>%
  dplyr::select(-name,-date,-time,-connection,-from.X,-from.Y,-to.X,-to.Y,-datetime,-X,-lat,-lng,-date_time,-interval60,-interval15) %>% 
  filter(country.code == 'be') %>% 
  st_drop_geometry() %>%
  na.omit()

data_f_reg$high_occ <- ifelse(data_f_reg$occupancy == "high", "Yes","No")
data_f_reg$high_occ_num <- ifelse(data_f_reg$occupancy == "high", 1,0)
# table(data_f_reg$high_occ)

set.seed(3456)
trainIndex <- createDataPartition(data_f_reg$occupancy, p = .65,
                                  list = FALSE,
                                  times = 1)
data_f_regTrain <- data_f_reg[ trainIndex,]
data_f_regTest  <- data_f_reg[-trainIndex,]


# m0 <- multinom(occupancy ~ from + to + avg_stop_times + facility_sum + temperature + humidity + windspeed + visibility + F_H_com + F_M_com + F_L_com + T_H_com + T_M_com + T_L_com + connections + week + day + hour + min + time_of_day + vehicle_type , data = na.omit(data_f_reg),MaxNWts =10000000)

# m1 <- multinom(occupancy ~ from + to + avg_stop_times + facility_sum + temperature + humidity + windspeed + visibility + F_H_com + F_M_com + F_L_com + T_H_com + T_M_com + T_L_com + connections + week + day + hour + min + vehicle_type + lagHour + lag2Hours + lag3Hours + lag4Hours + lag12Hours + time_of_day,  data = na.omit(data_f_reg),MaxNWts =10000000)

m0 <- glm(high_occ_num ~ from + to + avg_stop_times + facility_sum + temperature + humidity + windspeed + visibility + F_H_com + F_M_com + F_L_com + T_H_com + T_M_com + T_L_com + connections + week + day + hour + min + vehicle_type + time_of_day + stationsdist + distance,
          data = data_f_reg,
          family="binomial" (link="logit"))

m1 <- glm(high_occ_num ~ from + to + avg_stop_times + facility_sum + temperature + humidity + windspeed + visibility + F_H_com + F_M_com + F_L_com + T_H_com + T_M_com + T_L_com + connections + week + day + hour + min + vehicle_type + lagHour + lag2Hours + lag3Hours + lag4Hours + lag12Hours + time_of_day + stationsdist + distance,
          data = data_f_reg,
          family="binomial" (link="logit"))



stargazer(m0, m1, type = "html", 
          title = "Table 1. Summary Statistics of Model 1 and Model 2",
          header = FALSE,
          single.row = TRUE,
          column.labels=c("Model 1","Model 2"))


```



### 4.2 Occupancy Prediction

By leveraging the two models, we predict the occupancy level and generate two plots to show the distribution of predicted outcomes between the two models. Without distinguished differences, we cannot directly conclude which one is better so far. But since we are more concerned about the time-lag features in our model, we will stick on the Model 2 from now on. 

```{r Prediction and Plot, message=FALSE, warning=FALSE, fig.height = 8, fig.width = 8}
testProbs0 <- data.frame(Outcome0 = as.factor(data_f_reg$high_occ_num),
                        Probs0 = predict(m0, newdata = data_f_reg, na.rm = TRUE, type= "response" ))


testProbs1 <- data.frame(Outcome1 = as.factor(data_f_reg$high_occ_num),
                        Probs1 = predict(m1, newdata = data_f_reg, na.rm = TRUE, type= "response" ))

# View(testProbs1)

grid.arrange(
  ggplot(testProbs0, aes(x = Probs0, fill = as.factor(Outcome0))) + 
  geom_density() +
  facet_grid(Outcome0 ~ .) +
  scale_fill_manual(values = palette2,
                          name = "Predicated High Occupancy",
                    labels = c("Low/Medium", "High")) +
  labs(x = "Occupancy", y = "Density of probabilities",
       title = "Distribution of predicted probabilities by observed outcome - Model 1\n") +
  theme(strip.text.x = element_text(size = 18),
        legend.position = "bottom") +
  plotTheme(),

ggplot(testProbs1, aes(x = Probs1, fill = as.factor(Outcome1))) + 
  geom_density() +
  facet_grid(Outcome1 ~ .) +
  scale_fill_manual(values = palette2,
                          name = "Predicated High Occupancy",
                    labels = c("Low/Medium", "High")) +
  labs(x = "Occupancy", y = "Density of probabilities",
       title = "Distribution of predicted probabilities by observed outcome - Model 2\n",
       caption = 'Figure 4') +
  theme(strip.text.x = element_text(size = 18),
        legend.position = "bottom") +
  plotTheme())


```



## V. Model Evaluation and Validation

### 5.1 Good of Fit: Confusion Matrix

A “confusion matrix” for the threshold of 50% shows us the rate at which we got True Positives (aka Sensitivity), False Positives, True Negatives (aka Specificity) and False Negatives for that threshold.

In this case,
*    True Positives: Predicted correctly the occupancy of train is high.
*    False Positives: Predicted incorrectly the occupancy of train is high.
*    True Negatives: Predicted correctly the occupancy of train is not high.
*    False Negatives: Predicted incorrectly the occupancy of train is not high. 

This analysis more cares about sensitivity since the goal is to find out the stations with high occupancy level. So far, the sensitivity of the model is 0.47. 


```{r conf.matrix with description, echo=TRUE, message=FALSE, warning=FALSE}
testProbs1 <- 
  testProbs1 %>%
  mutate(predOutcome1  = as.factor(ifelse(testProbs1$Probs1 > 0.5 , 1, 0)))


caret::confusionMatrix(testProbs1$predOutcome1, testProbs1$Outcome1, 
                       positive = "1")

conf.matrix.table1 <-
   testProbs1 %>%
      count(predOutcome1, Outcome1) %>%
      summarize(True_Negative = sum(n[predOutcome1==0 & Outcome1==0]),
                True_Positive = sum(n[predOutcome1==1 & Outcome1==1]),
                False_Negative = sum(n[predOutcome1==0 & Outcome1==1]),
                False_Positive = sum(n[predOutcome1==1 & Outcome1==0])) %>%
       gather(Variable, Count) %>%
    bind_cols(data.frame(Description = c(
              "Predicted correctly the occupancy of train is not high",
              "Predicted correctly the occupancy of train is high",
              "Predicted incorrectly the occupancy of train is not high",
              "Predicted incorrectly the occupancy of train is high")))


kable(conf.matrix.table1) %>% 
  kable_styling(font_size = 12, full_width = F,
                bootstrap_options = c("striped", "hover", "condensed")) %>%
  footnote(general = "Table 2. Confusion Matrix Table\n",
           general_title= '\n')


```


### 5.2 Cross Validation on 100 k-folds

This section conducted cross-validation on both models. The outputs include the ROC, sensitivity and specificity across the 100 k-folds. The model generalizes well with regard to sensitivity. Since we are more concerned about the sensitivity as mentioned above, such an outcome is satisfied. 


```{r CV, message=FALSE, warning=FALSE}
ctrl <- trainControl(method = "cv", number = 100, classProbs=TRUE, summaryFunction = twoClassSummary)


cvFit.reg1 <- train(high_occ ~ from + to + avg_stop_times + facility_sum + temperature + humidity + windspeed + visibility + F_H_com + F_M_com + F_L_com + T_H_com + T_M_com + T_L_com + connections + week + day + hour + min + vehicle_type + lagHour + lag2Hours + lag3Hours + lag4Hours + lag12Hours + time_of_day + distance + stationsdist
                      , data = data_f_reg %>%
                  dplyr::mutate(y = ifelse(high_occ =="no","c1.yes","c1.no")), 
                method="glm", family="binomial",
                metric="ROC", trControl = ctrl)

```


```{r CV plots, message=FALSE, warning=FALSE}
dplyr::select(cvFit.reg1$resample, -Resample) %>%
  gather(metric, value) %>%
  left_join(gather(cvFit.reg1$results[2:4], metric, mean)) %>%
  ggplot(aes(value)) + 
    geom_histogram(bins=35, fill = "#3e7ec2") +
    facet_wrap(~metric) +
    geom_vline(aes(xintercept = mean), colour = "#981FAC", linetype = 3, size = 1.5) +
    scale_x_continuous(limits = c(0, 1)) +
    labs(x="Goodness of Fit", y="Count", 
         title="CV Goodness of Fit Metrics",
         subtitle = "Across-fold mean reprented as dotted lines\n",
         caption = "Figure 5.2") +
  plotTheme()


kable(cvFit.reg1$resample,
          caption = 'Table 3. RESULT. Cross-validation Test: Summary of ROC, Sensitivity, and Speciality') %>%
  kable_styling("striped", full_width = F) %>%
  scroll_box(width = "100%", height = "200px")
```


### 5.3 Model Generalization Across Space

This section creates two sets of plots to show how model prediction is generalized across stations. Basically, the model is well generalized across the stations. More wrong predictions occurred around Gent-Sint-Pieters, Brussel-Noord/Bruxelles-Nord, Brussel-Centraal/Bruxelles-Central, Brussel-Zuid, Leuven, Antwerpen-Centraal. Those are comparatively big stations around big cities, thus more factors migh affect the accuracy for prediction. 

```{r generalization across space, echo=TRUE, message=FALSE, warning=FALSE}
AA <- data_f_reg %>%
   mutate(Probs = predict(m1, newdata = data_f_reg, na.rm = TRUE, type= "response" ),
          Pred  = as.factor(ifelse(Probs > 0.5 , 1, 0))) %>%
  dplyr::select(rowIndex, high_occ,high_occ_num, Pred)


new_data <- merge(x = AA, y = data_f, by.x = "rowIndex") %>%
  mutate(CM = case_when(
    Pred == 0 & high_occ_num == 0 ~ 'TN',
    Pred == 0 & high_occ_num == 1 ~ 'FN',
    Pred == 1 & high_occ_num == 0 ~ 'FP',
    Pred == 1 & high_occ_num == 1 ~ 'TP'),
    Error = ifelse(Pred == high_occ_num, "Error", "No Error"))

# table(new_data$CM)
# View(new_data)

conf.matrix.station <- new_data %>%
  group_by(name, CM) %>%
  summarize(count = n())

conf.matrix.station.sf <- merge(x = conf.matrix.station, y = stations, by = "name" , all.x = TRUE)  %>%
  st_sf()

error.station <- new_data %>%
  group_by(name,Error) %>% 
  summarise(count = n())
  
# View(error.station)

error.station.sf <- merge(x = error.station, y = stations, by = "name" , all.x = TRUE)  %>%
  st_sf()
```



```{r Confustion Matrix Across Stations, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.height = 6, fig.width = 8}
ggplot() +
  geom_sf(data = rail, color = "grey") +  
  geom_sf(data = conf.matrix.station.sf %>%
            filter(country.code == 'be'), 
          aes(color = count), size = 1) +
  labs(title="Confustion Matrix Across Stations",
       subtitle = ' ',
       caption = 'Figure 5.3.1')+ 
  scale_colour_viridis(direction = -1,
  discrete = FALSE, option = "plasma",
  name = 'Counts')+
  facet_wrap(~CM) + 
  mapTheme()+
  plotTheme() 
```

```{r Error across Stations, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.height = 4, fig.width = 8}
ggplot() +
  geom_sf(data = rail, color = "grey") +  
  geom_sf(data = error.station.sf %>%
            filter(country.code == 'be'), 
          aes(color = count), size = 1) +
  labs(title="Prediction Errors Across Stations",
       subtitle = ' ',
       caption = 'Figure 5.3.2')+ 
  scale_colour_viridis(direction = -1,
  discrete = FALSE, option = "plasma",
  name = 'Counts')+
  facet_wrap(~Error) + 
  mapTheme()+
  plotTheme() 
```


### 5.4 ROC Curve for Model

Theoretically, the ROC curve indicates a TP vs. FP rate at one certain decision threshold, while AUC provides an aggregate measure of performance across all possible classification thresholds. Shown in the graph below, for every additional improvement in true positive rate, the model will make a greater proportion of false positive errors. Moving from a 75% to a 100% true positive rate dramatically increases the false positive rate. The trade-off has been triggered by such diminishing. 


The AUC of 0.7997 indicates that for the sake of ranking a random positive example more highly than a random negative example, this model need to set the threshold no less than 0.7997.

```{r ROC Curve, message=FALSE, warning=FALSE}
testProbs1$Outcome1 <- as.numeric(testProbs1$Outcome1)
# auc(testProbs1$Outcome1, testProbs1$Probs1)

ggplot(testProbs1, aes(d = as.numeric(testProbs1$Outcome1), m = Probs1)) +
  geom_roc(n.cuts = 50, labels = FALSE, colour = "#3e7ec2") +
  style_roc(theme = theme_grey) +
  geom_abline(slope = 1, intercept = 0, size = 1.5, color = '#a6dbbc') +
  labs(title = "ROC Curve - Model 1\n",
       caption = 'Figure') +
  plotTheme()
```

### 5.5 Thresholds Optimization

This section selects optimal thresholds by plotting the confusion matrix outcomes for each threshold. Graphs below indicate that with the increase of the threshold, there is no change of the confusion matrix outcome. This findings indicate that threshold might not needed to modify. 



```{r Optimize Thresholds, echo=TRUE, message=FALSE, warning=FALSE}
iterateThresholds <- function(data) {
  x = 0.01
  all_prediction <- data.frame()
  while (x <= 1) {
  
  this_prediction <-
      testProbs1 %>%
      mutate(predOutcome_new = ifelse(Probs1 > 0.5, 1, 0)) %>%
      count(predOutcome_new, Outcome1) %>%
      summarize(True_Negative = sum(n[predOutcome_new==0 & Outcome1==1]),
                True_Positive = sum(n[predOutcome_new==1 & Outcome1==2]),
                False_Negative = sum(n[predOutcome_new==0 & Outcome1==2]),
                False_Positive = sum(n[predOutcome_new==1 & Outcome1==1])) %>%
      gather(Variable, Count) %>%
      mutate(Threshold = x)
  
  all_prediction <- rbind(all_prediction, this_prediction)
  x <- x + .01
  }
return(all_prediction)
}


whichThreshold_subsidy <- iterateThresholds(testProbs1)
# View(whichThreshold_subsidy)

whichThreshold_subsidy  %>%
  ggplot(.,aes(Threshold, Count, colour = Variable)) +
  geom_point() +
  scale_colour_manual(values = palette4) +    
  labs(title = "Counts by confusion matrix type and threshold\n",
       y = "Count",
       caption = 'Figure 5.4') +
  plotTheme() +
  guides(colour=guide_legend(title = "Confusion Matrix")) 

whichThreshold_subsidy_new <- 
  whichThreshold_subsidy %>%
  group_by(Threshold) %>%
  summarise(Total_Count = sum(Count))

# View(whichThreshold_subsidy_new)

whichThreshold_subsidy_new %>%
  ggplot(aes(Threshold, Total_Count)) +
    geom_point(color =  "#658feb") +
    geom_vline(xintercept = dplyr::pull(arrange(whichThreshold_subsidy_new, -Total_Count)[1,1])) +
  ylab('Total Counts')  +
  labs(title = "Total Count of Credits by Threshold\n",
       caption = 'Figure 6.3')  + 
 plotTheme() 

```


## VI. Conclusion

### 6.1 Application

As shown above, a versatile App, named as **[BeRail](https://youtu.be/PrhAjW-pVkQ)** would be developed based on the algorithm in this project. There are two primary panels built in BeRail: dashboard and query. In the dashboard interface, transportation planners are able to see an overview of occupancy levels by time and space through various visualization tools such as summary tables, heat maps, bar charts, and plots. On the other hand, the query interface works as a filter engine in which transportation planners can set specific conditions such as station, line, date and time depending on different policy goals. The filtered result can be visualized in the app or exported as a usable data format for future use. 

![BeRail Dashboard Interface](/Users/penguin/Box Sync/GitHub/Final Project/interface.png)

#            
#             

![BeRail Query Interface](/Users/penguin/Box Sync/GitHub/Final Project/query.png)


Generally, this App would assist policy decision-making and help transportation planners to monitor train occupancy level and optimize the allocation of public resources while decreasing operational costs. For instance, to increase ridership and reduce resource waste, transportation planners can simply filter for stations with constant low occupancy. The result would pinpoint the stations as well as the community for infrastructure improvement. 

Connecting to the current situation, the benefits of this App is beyond the previous expectation that this app can help ensure a better distribution of travelers across the various trains and to avoid boarding an overly crowded train to reduce COVID-19 risks. 


### 6.2 Reflection

It is unfortunate that this project has shown some limitations some of which are inherent in the algorithm:

- First of all, for the sake of simplicity, this project transformed the three-level occupancy to the two-level occupancy. However, this initiative, to some extent, covers up the subtle differences between train lines with low occupancy level and medium occupancy level and hampers the prediction accuracy. For a better model, further efforts should be made on the development of an ordinal logistic regression model for an categorical independent variable which contains three and more, ordered levels.

- Secondly, instead of analyzing occupancy levels on the basis of each OD set, this project focuses on the occupancy level of each departure station and destination station. This initiative would be under question since the occupancy level should be used for describing the overall passenger density along the train line. However, since the amount of departure stations and the amount of the destination stations are different, such a combination would generate tons of null values across features. Building models on such data would barely capture the train line characteristics. Therefore, this project sets a premise that the overall occupancy levels are always consistent among each station along a certain line, and thus, we can analyze the potential occupancy level of each station.

- Thirdly, an innate limitation is that this project is built on four-year ago pre-existing data covering only four months. The poor data accessibility disturbs the accuracy and generalization of the algorithm. On the other hand, without real-time data and detailed data on the passengers’ characteristics, such as the trip purposes, special service, the current algorithm might ignore details that result in low accuracy. 


Despite the limitations, we still believe this project is beneficial to city planners and train conductors. The previous situations can always shed light on the present problem, and help produce an annual report on the train operation and further improvements.
